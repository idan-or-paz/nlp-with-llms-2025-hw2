{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c468709d",
   "metadata": {},
   "source": [
    "# ImpPres LLM Baseline\n",
    "\n",
    "You have to implement in this notebook a baseline for ImpPres classification using an LLM.\n",
    "This baseline must be implemented using DSPy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2cec0d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the DSPy environment with the language model - for grok the parameters must be:\n",
    "# env variable should be in os.environ['XAI_API_KEY']\n",
    "# \"xai/grok-3-mini\"\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import dspy\n",
    "load_dotenv(\"grok_key.ini\") \n",
    "lm = dspy.LM('xai/grok-3-mini', api_key=os.environ['XAI_API_KEY'])\n",
    "\n",
    "\n",
    "\n",
    "# for ollama \n",
    "# lm = dspy.LM('ollama_chat/devstral', api_base='http://localhost:11434', api_key='')\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4d566d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from tqdm import tqdm\n",
    "import dspy\n",
    "\n",
    "# Signature for the NLI task\n",
    "class NLISignature(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Classify the relationship between the premise and hypothesis \n",
    "    to a label: entailment, neutral or contradiction.\n",
    "    \"\"\"\n",
    "    premise: str = dspy.InputField()\n",
    "    hypothesis: str = dspy.InputField()\n",
    "    label: Literal['entailment', 'neutral', 'contradiction'] = dspy.OutputField()\n",
    "\n",
    "# A class for Parallel processing with progress display\n",
    "class NLIClassifier(dspy.Module):\n",
    "    def __init__(self, predictor_module: dspy.Module, batch_size: int = 15, num_threads: int = 6):\n",
    "        super().__init__()\n",
    "        self.predictor = predictor_module  # Predict, ChainOfThought, etc.\n",
    "        self.batch_size = batch_size\n",
    "        self.num_threads = num_threads\n",
    "\n",
    "    def forward(self, examples: dspy.Example) -> list[dspy.Prediction]:\n",
    "        # Display progress with tqdm while processing\n",
    "        results = []\n",
    "        for i in tqdm(range(0, len(examples), self.batch_size), desc=\"Processing\"):\n",
    "            sub_batch = examples[i:i + self.batch_size]\n",
    "            processed = self.predictor.batch( # perform batch processing\n",
    "                sub_batch,\n",
    "                num_threads=self.num_threads\n",
    "            )\n",
    "            results.extend(processed)\n",
    "\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ab422d",
   "metadata": {},
   "source": [
    "## Load ImpPres dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0438789b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset for section: presupposition_all_n_presupposition\n",
      "Loading dataset for section: presupposition_both_presupposition\n",
      "Loading dataset for section: presupposition_change_of_state\n",
      "Loading dataset for section: presupposition_cleft_existence\n",
      "Loading dataset for section: presupposition_cleft_uniqueness\n",
      "Loading dataset for section: presupposition_only_presupposition\n",
      "Loading dataset for section: presupposition_possessed_definites_existence\n",
      "Loading dataset for section: presupposition_possessed_definites_uniqueness\n",
      "Loading dataset for section: presupposition_question_presupposition\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "sections = ['presupposition_all_n_presupposition', \n",
    "            'presupposition_both_presupposition', \n",
    "            'presupposition_change_of_state', \n",
    "            'presupposition_cleft_existence', \n",
    "            'presupposition_cleft_uniqueness', \n",
    "            'presupposition_only_presupposition', \n",
    "            'presupposition_possessed_definites_existence', \n",
    "            'presupposition_possessed_definites_uniqueness', \n",
    "            'presupposition_question_presupposition']\n",
    "\n",
    "dataset = {}\n",
    "for section in sections:\n",
    "    print(f\"Loading dataset for section: {section}\")\n",
    "    dataset[section] = load_dataset(\"facebook/imppres\", section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e59927ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'presupposition_all_n_presupposition': DatasetDict({\n",
       "     all_n_presupposition: Dataset({\n",
       "         features: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID'],\n",
       "         num_rows: 1900\n",
       "     })\n",
       " }),\n",
       " 'presupposition_both_presupposition': DatasetDict({\n",
       "     both_presupposition: Dataset({\n",
       "         features: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID'],\n",
       "         num_rows: 1900\n",
       "     })\n",
       " }),\n",
       " 'presupposition_change_of_state': DatasetDict({\n",
       "     change_of_state: Dataset({\n",
       "         features: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID'],\n",
       "         num_rows: 1900\n",
       "     })\n",
       " }),\n",
       " 'presupposition_cleft_existence': DatasetDict({\n",
       "     cleft_existence: Dataset({\n",
       "         features: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID'],\n",
       "         num_rows: 1900\n",
       "     })\n",
       " }),\n",
       " 'presupposition_cleft_uniqueness': DatasetDict({\n",
       "     cleft_uniqueness: Dataset({\n",
       "         features: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID'],\n",
       "         num_rows: 1900\n",
       "     })\n",
       " }),\n",
       " 'presupposition_only_presupposition': DatasetDict({\n",
       "     only_presupposition: Dataset({\n",
       "         features: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID'],\n",
       "         num_rows: 1900\n",
       "     })\n",
       " }),\n",
       " 'presupposition_possessed_definites_existence': DatasetDict({\n",
       "     possessed_definites_existence: Dataset({\n",
       "         features: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID'],\n",
       "         num_rows: 1900\n",
       "     })\n",
       " }),\n",
       " 'presupposition_possessed_definites_uniqueness': DatasetDict({\n",
       "     possessed_definites_uniqueness: Dataset({\n",
       "         features: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID'],\n",
       "         num_rows: 1900\n",
       "     })\n",
       " }),\n",
       " 'presupposition_question_presupposition': DatasetDict({\n",
       "     question_presupposition: Dataset({\n",
       "         features: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID'],\n",
       "         num_rows: 1900\n",
       "     })\n",
       " })}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8e1258",
   "metadata": {},
   "source": [
    "## Evaluate Metrics\n",
    "\n",
    "Let's use the huggingface `evaluate` package to compute the performance of the baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1ab24e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "clf_metrics = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0909d58b",
   "metadata": {},
   "source": [
    "## Your Turn\n",
    "\n",
    "Compute the classification metrics on the baseline LLM model on each test section of the ANLI dataset for samples that have a non-empty 'reason' field.\n",
    "\n",
    "You also must show a comparison between the DeBERTa baseline model and this LLM baseline model. The comparison metric should compute the agreement between the two models:\n",
    "* On how many samples they are both correct [Correct]\n",
    "* On how many samples Model1 is correct and Model2 is incorrect [Correct1]\n",
    "* On how many samples Model1 is incorrect and Model2 is correct [Correct2]\n",
    "* On how many samples both are incorrect [Incorrect]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79c9a4d",
   "metadata": {},
   "source": [
    "# IMPORTANT NOTE:\n",
    "\n",
    "Following discussing with Michael - it was agreed that we use smaller sample than the whole impPres data set (17,000 samples) , as long as it is diverse.\n",
    "So - we took 212 samples from each of the 9 data sets , summing up to 1908 examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8631ce1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples: 1908\n"
     ]
    }
   ],
   "source": [
    "# Organizing the dataset into examples\n",
    "\n",
    "section_to_split = {\n",
    "    'presupposition_all_n_presupposition': 'all_n_presupposition',\n",
    "    'presupposition_both_presupposition': 'both_presupposition',\n",
    "    'presupposition_change_of_state': 'change_of_state',\n",
    "    'presupposition_cleft_existence': 'cleft_existence',\n",
    "    'presupposition_cleft_uniqueness': 'cleft_uniqueness',\n",
    "    'presupposition_only_presupposition': 'only_presupposition',\n",
    "    'presupposition_possessed_definites_existence': 'possessed_definites_existence',\n",
    "    'presupposition_possessed_definites_uniqueness': 'possessed_definites_uniqueness',\n",
    "    'presupposition_question_presupposition': 'question_presupposition',\n",
    "}\n",
    "\n",
    "preprocessed_examples = [\n",
    "    dspy.Example(\n",
    "        premise=row[\"premise\"],\n",
    "        hypothesis=row[\"hypothesis\"],\n",
    "        label=row[\"gold_label\"]\n",
    "    ).with_inputs(\"premise\", \"hypothesis\")\n",
    "    for k, v in section_to_split.items()\n",
    "    for row in dataset[k][v]\n",
    "]\n",
    "\n",
    "# use the first 212 examples for each section (in total ~1900 examples)\n",
    "examples = []\n",
    "for i in range(len(section_to_split)):\n",
    "    start_index = i * 212\n",
    "    end_index = start_index + 212\n",
    "    examples.extend(preprocessed_examples[start_index:end_index])\n",
    "\n",
    "print(f\"Total examples: {len(examples)}\")\n",
    "\n",
    "\n",
    "# Orgnaizing the data sets set\n",
    "# pick examples randomly for training\n",
    "import random\n",
    "train_set_size = 30 # tradeoff between quality and speed after testing\n",
    "trainset = random.sample(examples[:len(examples)//2], train_set_size) # pick examples from the first half to avoid bias\n",
    "\n",
    "\n",
    "# pick examples randomly for evaluation\n",
    "eval_set_size = 60  # size of the evaluation set\n",
    "evaluate_set = random.sample(examples[len(examples)//2:], eval_set_size)\n",
    "\n",
    "# unrequired verbosity\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\".*encoder_attention_mask.*\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a1f935",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [00:30<03:20,  7.70s/it]\n",
      "2025/08/07 20:12:50 INFO dspy.teleprompt.copro_optimizer: Iteration Depth: 1/2.\n",
      "2025/08/07 20:12:50 INFO dspy.teleprompt.copro_optimizer: At Depth 1/2, Evaluating Prompt Candidate #1/3 for Predictor 1 of 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 4 examples for up to 1 rounds, amounting to 4 attempts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/07 20:13:13 INFO dspy.evaluate.evaluate: Average Metric: 27 / 30 (90.0%)\n",
      "2025/08/07 20:13:13 INFO dspy.teleprompt.copro_optimizer: At Depth 1/2, Evaluating Prompt Candidate #2/3 for Predictor 1 of 1.\n",
      "2025/08/07 20:13:39 INFO dspy.evaluate.evaluate: Average Metric: 29 / 30 (96.7%)\n",
      "2025/08/07 20:13:39 INFO dspy.teleprompt.copro_optimizer: At Depth 1/2, Evaluating Prompt Candidate #3/3 for Predictor 1 of 1.\n",
      "2025/08/07 20:14:05 INFO dspy.evaluate.evaluate: Average Metric: 28 / 30 (93.3%)\n",
      "2025/08/07 20:14:12 INFO dspy.teleprompt.copro_optimizer: Iteration Depth: 2/2.\n",
      "2025/08/07 20:14:12 INFO dspy.teleprompt.copro_optimizer: At Depth 2/2, Evaluating Prompt Candidate #1/3 for Predictor 1 of 1.\n",
      "2025/08/07 20:14:39 INFO dspy.evaluate.evaluate: Average Metric: 27 / 30 (90.0%)\n",
      "2025/08/07 20:14:39 INFO dspy.teleprompt.copro_optimizer: At Depth 2/2, Evaluating Prompt Candidate #2/3 for Predictor 1 of 1.\n",
      "2025/08/07 20:15:06 INFO dspy.evaluate.evaluate: Average Metric: 28 / 30 (93.3%)\n",
      "2025/08/07 20:15:07 INFO dspy.teleprompt.copro_optimizer: At Depth 2/2, Evaluating Prompt Candidate #3/3 for Predictor 1 of 1.\n",
      "2025/08/07 20:15:35 INFO dspy.evaluate.evaluate: Average Metric: 26 / 30 (86.7%)\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import BootstrapFewShot, COPRO, KNNFewShot\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import evaluate\n",
    "\n",
    "# Load metrics\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "\n",
    "label2id = {\"entailment\": 0, \"neutral\": 1, \"contradiction\": 2}\n",
    "\n",
    "def exact_match(example, pred, trace=None):\n",
    "    # Ensure both labels are strings and lowercase\n",
    "    ex_label = str(example.label).strip().lower()\n",
    "    pred_label = str(pred.label).strip().lower()\n",
    "\n",
    "    # In case example.label is already an int, use reverse mapping\n",
    "    if ex_label.isdigit():\n",
    "        id2label = {v: k for k, v in label2id.items()}\n",
    "        ex_label = id2label[int(ex_label)]\n",
    "\n",
    "    return label2id.get(pred_label) == label2id.get(ex_label)\n",
    "\n",
    "def compute_metrics(preds, golds):\n",
    "    return {\n",
    "        \"accuracy\": accuracy.compute(predictions=preds, references=golds)[\"accuracy\"],\n",
    "        \"precision\": precision.compute(predictions=preds, references=golds, average=\"macro\")[\"precision\"],\n",
    "        \"recall\": recall.compute(predictions=preds, references=golds, average=\"macro\")[\"recall\"],\n",
    "        \"f1\": f1.compute(predictions=preds, references=golds, average=\"macro\")[\"f1\"],\n",
    "    }\n",
    "\n",
    "# Prepare models\n",
    "model_simple = dspy.Predict(NLISignature)\n",
    "model_cot = dspy.ChainOfThought(NLISignature)\n",
    "\n",
    "# --- Optimization phase ---\n",
    "# 1. BootstrapFewShot\n",
    "bootstrap = BootstrapFewShot(metric=exact_match)\n",
    "optimized_bootstrap = bootstrap.compile(student=model_simple, trainset=trainset)\n",
    "\n",
    "# 2. COPRO on our cot model\n",
    "copro = COPRO(metric=exact_match, max_trials=5, depth=2, breadth=3)\n",
    "optimized_cot = copro.compile(student=model_cot, trainset=trainset,eval_kwargs={})\n",
    "\n",
    "# # 3. KNNFewShot\n",
    "# class EmbedderWrapper:\n",
    "#     def __init__(self, model_name): self.model = SentenceTransformer(model_name)\n",
    "#     def __call__(self, texts): return self.model.encode(texts, convert_to_numpy=True)\n",
    "\n",
    "# vectorizer = EmbedderWrapper('all-MiniLM-L6-v2')\n",
    "# knn = KNNFewShot(k=5, trainset=trainset, vectorizer=vectorizer)\n",
    "# optimized_knn = knn.compile(student=model_simple)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "863fac03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Evaluating Models... this might take a long time... adjust eval_set_size , train_set_size to speed up the process\n",
      "📊 Model Evaluation Results:\n",
      "\n",
      "{'BootstrapFewShot': {'accuracy': 0.9833333333333333,\n",
      "                      'f1': 0.9808187134502924,\n",
      "                      'precision': 0.9885057471264368,\n",
      "                      'recall': 0.9743589743589745},\n",
      " 'COPRO_CoT': {'accuracy': 0.9333333333333333,\n",
      "               'f1': 0.9358730158730159,\n",
      "               'precision': 0.9583333333333334,\n",
      "               'recall': 0.921727395411606}}\n"
     ]
    }
   ],
   "source": [
    "import contextlib\n",
    "import io\n",
    "\n",
    "# --- Evaluation phase (Silent Mode) ---\n",
    "\n",
    "print(\"📊 Evaluating Models... this might take a long time... adjust eval_set_size , train_set_size to speed up the process\")\n",
    "\n",
    "results = {}\n",
    "silent_output = io.StringIO()\n",
    "optimized_dict = {\n",
    "    \"BootstrapFewShot\": optimized_bootstrap,\n",
    "    \"COPRO_CoT\": optimized_cot,\n",
    "    # \"KNNFewShot\": optimized_knn,\n",
    "}\n",
    "\n",
    "with contextlib.redirect_stdout(silent_output), contextlib.redirect_stderr(silent_output):\n",
    "    for name, predictor in optimized_dict.items():\n",
    "        program = NLIClassifier(predictor_module=predictor)\n",
    "        predictions = program(evaluate_set) # \"forward\" method is called implicitly\n",
    "\n",
    "        y_true = [ex.label for ex in evaluate_set[:len(predictions)]]\n",
    "        y_pred = [label2id[pred.label.strip().lower()] for pred in predictions]\n",
    "\n",
    "        results[name] = compute_metrics(y_pred, y_true)\n",
    "\n",
    "# --- Display results ---\n",
    "from pprint import pprint\n",
    "print(\"📊 Model Evaluation Results:\\n\")\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1638816f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As you can see from the above output, BootstrapFewShot has the highest scores.\n",
    "# reference output:\n",
    "\n",
    "# {'BootstrapFewShot': {'accuracy': 0.9833333333333333,\n",
    "#                       'f1': 0.9808187134502924,\n",
    "#                       'precision': 0.9885057471264368,\n",
    "#                       'recall': 0.9743589743589745},\n",
    "#  'COPRO_CoT': {'accuracy': 0.9333333333333333,\n",
    "#                'f1': 0.9358730158730159,\n",
    "#                'precision': 0.9583333333333334,\n",
    "#                'recall': 0.921727395411606}}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9637e5f6",
   "metadata": {},
   "source": [
    "# The best performing model is optimized_bootstrap -> BootstrapFewShot ,  which automates the creation of effective few-shot demonstrations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "81ff8a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:19<00:00,  1.33s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   1%|          | 1/128 [00:20<42:21, 20.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:23<00:00,  1.58s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   2%|▏         | 2/128 [00:43<46:37, 22.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:25<00:00,  1.72s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   2%|▏         | 3/128 [01:09<49:40, 23.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:15<00:00,  1.03s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 4/128 [01:25<42:28, 20.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:22<00:00,  1.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|▍         | 5/128 [01:47<43:43, 21.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:17<00:00,  1.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   5%|▍         | 6/128 [02:05<41:00, 20.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:21<00:00,  1.41s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   5%|▌         | 7/128 [02:26<41:19, 20.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:15<00:00,  1.04s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   6%|▋         | 8/128 [02:42<37:53, 18.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:14<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   7%|▋         | 9/128 [02:57<34:53, 17.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:14<00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   8%|▊         | 10/128 [03:11<32:55, 16.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:16<00:00,  1.10s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   9%|▊         | 11/128 [03:28<32:31, 16.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:13<00:00,  1.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   9%|▉         | 12/128 [03:42<30:26, 15.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:12<00:00,  1.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  10%|█         | 13/128 [03:54<28:07, 14.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:13<00:00,  1.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  11%|█         | 14/128 [04:07<27:17, 14.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:13<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  12%|█▏        | 15/128 [04:21<26:29, 14.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:12<00:00,  1.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  12%|█▎        | 16/128 [04:33<25:18, 13.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:24<00:00,  1.65s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  13%|█▎        | 17/128 [04:58<31:18, 16.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:11<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  14%|█▍        | 18/128 [05:10<28:12, 15.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:19<00:00,  1.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  15%|█▍        | 19/128 [05:29<30:08, 16.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:16<00:00,  1.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  16%|█▌        | 20/128 [05:46<29:57, 16.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:18<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  16%|█▋        | 21/128 [06:05<30:45, 17.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:15<00:00,  1.01s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  17%|█▋        | 22/128 [06:20<29:22, 16.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:12<00:00,  1.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  18%|█▊        | 23/128 [06:33<27:05, 15.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:15<00:00,  1.03s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  19%|█▉        | 24/128 [06:48<26:52, 15.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:17<00:00,  1.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  20%|█▉        | 25/128 [07:06<27:51, 16.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:14<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  20%|██        | 26/128 [07:20<26:31, 15.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:14<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  21%|██        | 27/128 [07:35<25:47, 15.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:15<00:00,  1.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  22%|██▏       | 28/128 [07:51<25:48, 15.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:16<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  23%|██▎       | 29/128 [08:08<26:14, 15.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:13<00:00,  1.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  23%|██▎       | 30/128 [08:21<24:52, 15.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:14<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  24%|██▍       | 31/128 [08:36<24:21, 15.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:14<00:00,  1.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  25%|██▌       | 32/128 [08:51<24:03, 15.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:16<00:00,  1.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  26%|██▌       | 33/128 [09:07<24:33, 15.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:20<00:00,  1.34s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  27%|██▋       | 34/128 [09:28<26:26, 16.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:12<00:00,  1.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  27%|██▋       | 35/128 [09:40<24:01, 15.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:13<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  28%|██▊       | 36/128 [09:53<22:50, 14.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:24<00:00,  1.64s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  29%|██▉       | 37/128 [10:18<27:00, 17.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:15<00:00,  1.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  30%|██▉       | 38/128 [10:34<25:52, 17.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:18<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  30%|███       | 39/128 [10:52<26:10, 17.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:17<00:00,  1.17s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  31%|███▏      | 40/128 [11:10<25:50, 17.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:15<00:00,  1.00s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  32%|███▏      | 41/128 [11:25<24:26, 16.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:16<00:00,  1.08s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  33%|███▎      | 42/128 [11:41<23:52, 16.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:14<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  34%|███▎      | 43/128 [11:56<22:35, 15.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:14<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  34%|███▍      | 44/128 [12:10<21:37, 15.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:16<00:00,  1.08s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  35%|███▌      | 45/128 [12:26<21:41, 15.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:15<00:00,  1.01s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  36%|███▌      | 46/128 [12:41<21:13, 15.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:14<00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  37%|███▋      | 47/128 [12:56<20:40, 15.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:14<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  38%|███▊      | 48/128 [13:11<20:10, 15.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:14<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  38%|███▊      | 49/128 [13:25<19:37, 14.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:16<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  39%|███▉      | 50/128 [13:42<20:11, 15.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:13<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  40%|███▉      | 51/128 [13:55<19:03, 14.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:14<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  41%|████      | 52/128 [14:10<18:37, 14.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:13<00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  41%|████▏     | 53/128 [14:23<17:46, 14.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:13<00:00,  1.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  42%|████▏     | 54/128 [14:36<17:13, 13.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:31<00:00,  2.10s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  43%|████▎     | 55/128 [15:08<23:26, 19.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:17<00:00,  1.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  44%|████▍     | 56/128 [15:26<22:37, 18.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:23<00:00,  1.60s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  45%|████▍     | 57/128 [15:50<24:08, 20.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:17<00:00,  1.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  45%|████▌     | 58/128 [16:08<22:57, 19.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:12<00:00,  1.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  46%|████▌     | 59/128 [16:20<20:13, 17.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:19<00:00,  1.32s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  47%|████▋     | 60/128 [16:40<20:42, 18.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:15<00:00,  1.01s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  48%|████▊     | 61/128 [16:56<19:22, 17.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:12<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  48%|████▊     | 62/128 [17:08<17:22, 15.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:14<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  49%|████▉     | 63/128 [17:22<16:35, 15.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:15<00:00,  1.04s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  50%|█████     | 64/128 [17:38<16:26, 15.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:13<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  51%|█████     | 65/128 [17:51<15:28, 14.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:12<00:00,  1.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  52%|█████▏    | 66/128 [18:03<14:37, 14.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:11<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  52%|█████▏    | 67/128 [18:15<13:36, 13.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:14<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  53%|█████▎    | 68/128 [18:30<13:46, 13.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:11<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  54%|█████▍    | 69/128 [18:42<12:56, 13.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:11<00:00,  1.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  55%|█████▍    | 70/128 [18:54<12:23, 12.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:14<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  55%|█████▌    | 71/128 [19:08<12:41, 13.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:16<00:00,  1.07s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  56%|█████▋    | 72/128 [19:24<13:13, 14.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:13<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  57%|█████▋    | 73/128 [19:38<12:47, 13.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:15<00:00,  1.02s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  58%|█████▊    | 74/128 [19:53<12:56, 14.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:16<00:00,  1.10s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  59%|█████▊    | 75/128 [20:10<13:15, 15.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:18<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  59%|█████▉    | 76/128 [20:28<13:56, 16.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:20<00:00,  1.33s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  60%|██████    | 77/128 [20:48<14:41, 17.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:13<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  61%|██████    | 78/128 [21:01<13:22, 16.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:14<00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  62%|██████▏   | 79/128 [21:16<12:48, 15.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:12<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  62%|██████▎   | 80/128 [21:28<11:41, 14.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:13<00:00,  1.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  63%|██████▎   | 81/128 [21:42<11:08, 14.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:12<00:00,  1.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  64%|██████▍   | 82/128 [21:55<10:36, 13.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:20<00:00,  1.36s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  65%|██████▍   | 83/128 [22:15<11:51, 15.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:12<00:00,  1.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  66%|██████▌   | 84/128 [22:27<10:49, 14.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:14<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  66%|██████▋   | 85/128 [22:42<10:27, 14.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:14<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  67%|██████▋   | 86/128 [22:56<10:15, 14.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:13<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  68%|██████▊   | 87/128 [23:10<09:49, 14.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:14<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  69%|██████▉   | 88/128 [23:25<09:36, 14.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:22<00:00,  1.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  70%|██████▉   | 89/128 [23:47<10:58, 16.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:34<00:00,  2.27s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  70%|███████   | 90/128 [24:21<13:57, 22.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:19<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  71%|███████   | 91/128 [24:40<13:03, 21.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:24<00:00,  1.63s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  72%|███████▏  | 92/128 [25:05<13:18, 22.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:24<00:00,  1.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  73%|███████▎  | 93/128 [25:29<13:18, 22.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:17<00:00,  1.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  73%|███████▎  | 94/128 [25:47<12:06, 21.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:17<00:00,  1.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  74%|███████▍  | 95/128 [26:05<11:11, 20.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:21<00:00,  1.44s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  75%|███████▌  | 96/128 [26:27<11:04, 20.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:20<00:00,  1.35s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  76%|███████▌  | 97/128 [26:47<10:38, 20.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:13<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  77%|███████▋  | 98/128 [27:01<09:17, 18.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:15<00:00,  1.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  77%|███████▋  | 99/128 [27:17<08:35, 17.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:11<00:00,  1.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  78%|███████▊  | 100/128 [27:29<07:28, 16.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:15<00:00,  1.04s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  79%|███████▉  | 101/128 [27:44<07:08, 15.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:14<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  80%|███████▉  | 102/128 [27:59<06:44, 15.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:14<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  80%|████████  | 103/128 [28:14<06:22, 15.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:09<00:00,  1.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  81%|████████▏ | 104/128 [28:23<05:24, 13.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:36<00:00,  2.42s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  82%|████████▏ | 105/128 [29:00<07:48, 20.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:22<00:00,  1.47s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  83%|████████▎ | 106/128 [29:22<07:39, 20.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:15<00:00,  1.04s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  84%|████████▎ | 107/128 [29:37<06:46, 19.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:18<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  84%|████████▍ | 108/128 [29:56<06:21, 19.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:24<00:00,  1.61s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  85%|████████▌ | 109/128 [30:20<06:31, 20.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:12<00:00,  1.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  86%|████████▌ | 110/128 [30:33<05:28, 18.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:15<00:00,  1.03s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  87%|████████▋ | 111/128 [30:48<04:56, 17.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:18<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  88%|████████▊ | 112/128 [31:07<04:46, 17.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:23<00:00,  1.59s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  88%|████████▊ | 113/128 [31:31<04:55, 19.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:13<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  89%|████████▉ | 114/128 [31:45<04:09, 17.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:14<00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  90%|████████▉ | 115/128 [32:00<03:40, 16.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:33<00:00,  2.25s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  91%|█████████ | 116/128 [32:34<04:24, 22.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:17<00:00,  1.17s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  91%|█████████▏| 117/128 [32:51<03:47, 20.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:13<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  92%|█████████▏| 118/128 [33:05<03:06, 18.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:14<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  93%|█████████▎| 119/128 [33:19<02:36, 17.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:15<00:00,  1.03s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  94%|█████████▍| 120/128 [33:35<02:14, 16.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:16<00:00,  1.07s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  95%|█████████▍| 121/128 [33:51<01:56, 16.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:13<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  95%|█████████▌| 122/128 [34:05<01:34, 15.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:21<00:00,  1.41s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  96%|█████████▌| 123/128 [34:26<01:26, 17.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:25<00:00,  1.68s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  97%|█████████▋| 124/128 [34:51<01:18, 19.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:18<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  98%|█████████▊| 125/128 [35:10<00:58, 19.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:12<00:00,  1.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  98%|█████████▊| 126/128 [35:23<00:34, 17.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 15 / 15 examples: 100%|██████████| 15/15 [00:19<00:00,  1.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  99%|█████████▉| 127/128 [35:42<00:18, 18.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 3 / 3 examples: 100%|██████████| 3/3 [00:05<00:00,  1.98s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 128/128 [35:48<00:00, 16.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# run the best model on all of the examples , and report the results\n",
    "best_model = optimized_bootstrap\n",
    "program = NLIClassifier(predictor_module=best_model)\n",
    "predictions = program.forward(examples)\n",
    "y_true = [ex.label for ex in examples]\n",
    "y_pred = [label2id[pred.label.strip().lower()] for pred in predictions]\n",
    "# Compute final metrics\n",
    "final_results = compute_metrics(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91901ac4",
   "metadata": {},
   "source": [
    "# TASK 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bb4666",
   "metadata": {},
   "source": [
    "Compute the classification metrics on the baseline LLM model on each test section of the ANLI dataset for samples that have a non-empty 'reason' field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "cac0f6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "\n",
      "\n",
      " -> Final Evaluation Results on All Examples: <- \n",
      "Accuracy: 0.9858490566037735, \n",
      "F1: 0.985355433901831, \n",
      "Precision: 0.9889684783159963, \n",
      "Recall: 0.9823544187906642 \n",
      "\n",
      "\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n"
     ]
    }
   ],
   "source": [
    "print(\"@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\")\n",
    "print(\"\\n\")\n",
    "print(\" -> Final Evaluation Results on All Examples: <- \\n\"\n",
    "      f\"Accuracy: {final_results['accuracy']}, \\n\"\n",
    "      f\"F1: {final_results['f1']}, \\n\"\n",
    "      f\"Precision: {final_results['precision']}, \\n\"\n",
    "      f\"Recall: {final_results['recall']} \\n\")\n",
    "print(\"\\n\")\n",
    "print(\"@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91ddd3d",
   "metadata": {},
   "source": [
    "You also must show a comparison between the DeBERTa baseline model and this LLM baseline model. The comparison metric should compute the agreement between the two models:\n",
    "* On how many samples they are both correct [Correct]\n",
    "* On how many samples Model1 is correct and Model2 is incorrect [Correct1]\n",
    "* On how many samples Model1 is incorrect and Model2 is correct [Correct2]\n",
    "* On how many samples both are incorrect [Incorrect]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7fec8608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both models are correct on 879 out of 1908 samples.\n",
      "Both models are correct on 46.07% of the samples.\n",
      "\n",
      "\n",
      "LLM is correct and DeBERTa_v3 is incorrect on 994 out of 1908 samples.\n",
      "LLM is correct and DeBERTa_v3 is incorrect on 52.10% of the samples.\n",
      "\n",
      "\n",
      "DeBERTa_v3 is correct and LLM is incorrect on 0 out of 1908 samples.\n",
      "DeBERTa_v3 is correct and LLM is incorrect on 0.00% of the samples.\n",
      "\n",
      "\n",
      "Both models are incorrect on 27 out of 1908 samples.\n",
      "Both models are incorrect on 1.42% of the samples.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# how many samples they are both correct\n",
    "%store -r DeBERTa_v3_predictions\n",
    "optimized_llm_predictions = predictions\n",
    "TEST_SIZE = len(optimized_llm_predictions)\n",
    "\n",
    "non_llm_predictions = []\n",
    "for i in range(len(section_to_split)):\n",
    "    start_index = i * 212\n",
    "    end_index = start_index + 212\n",
    "    non_llm_predictions.extend(DeBERTa_v3_predictions[start_index:end_index])\n",
    "\n",
    "# on how many samples both models are correct\n",
    "correct_predictions = sum(\n",
    "    1 for pred, llm_pred in zip(non_llm_predictions,optimized_llm_predictions)\n",
    "    if (llm_pred.label == pred['gold_label']) and (pred['gold_label'] == pred['pred_label'])\n",
    ")\n",
    "\n",
    "print(f\"Both models are correct on {correct_predictions} out of {TEST_SIZE} samples.\")\n",
    "print(f\"Both models are correct on {correct_predictions / TEST_SIZE * 100:.2f}% of the samples.\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# On how many samples llm is correct and DeBERTa_v3_ is incorrect\n",
    "llm_correct_deberta_incorrect = sum(\n",
    "    1 for pred, llm_pred in zip(non_llm_predictions,optimized_llm_predictions)\n",
    "    if (llm_pred.label == pred['gold_label']) and (pred['gold_label'] != pred['pred_label'])\n",
    ")\n",
    "print(f\"LLM is correct and DeBERTa_v3 is incorrect on {llm_correct_deberta_incorrect} out of {TEST_SIZE} samples.\")\n",
    "print(f\"LLM is correct and DeBERTa_v3 is incorrect on {llm_correct_deberta_incorrect / TEST_SIZE * 100:.2f}% of the samples.\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# On how many samples DeBERTa_v3 is correct and llm is incorrect\n",
    "deberta_correct_llm_incorrect = sum(\n",
    "    1 for pred, llm_pred in zip(non_llm_predictions,optimized_llm_predictions)\n",
    "    if (pred['pred_label'] == pred['gold_label']) and (llm_pred.label != pred['gold_label'])\n",
    ")\n",
    "print(f\"DeBERTa_v3 is correct and LLM is incorrect on {deberta_correct_llm_incorrect} out of {TEST_SIZE} samples.\")\n",
    "print(f\"DeBERTa_v3 is correct and LLM is incorrect on {deberta_correct_llm_incorrect / TEST_SIZE * 100:.2f}% of the samples.\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# on how many samples both models are incorrect\n",
    "both_incorrect = sum(\n",
    "    1 for pred, llm_pred in zip(non_llm_predictions,optimized_llm_predictions)\n",
    "    if (llm_pred.label != pred['gold_label']) and (pred['pred_label'] != pred['gold_label'])\n",
    ")\n",
    "print(f\"Both models are incorrect on {both_incorrect} out of {TEST_SIZE} samples.\")\n",
    "print(f\"Both models are incorrect on {both_incorrect / TEST_SIZE * 100:.2f}% of the samples.\")\n",
    "print(\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
